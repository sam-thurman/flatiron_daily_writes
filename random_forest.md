### Random Forest Regeression/Classification

A random forest algorithm in essence makes a bunch of decision trees using different criteria at random.  These decision trees will all have varying levels of success and some may be overfit.  The random forest algorithm is useful because all of these overfitted models will get 'smoothed out' when you use them togethr with all of the other models to make your prediction.  There are ways to hyper parameter tuning is easy with something called a grid search.  Random Forest models in scikit-learn have this built in as a GridSearchCV() and you fit and use it the same as most other scikit-learn objects.  The idea with a grid search for hyper paramter tuning is that the algorithm is looping through a parameter grid that you set(a dictionary of parameters as keys and arrays of values) and applying it to the different random trees generated by your Random Forest Regressor/Classifier.  The GridSearch can provide useful insights into the usefulness of your features, and the most useful parameters to use in your model.